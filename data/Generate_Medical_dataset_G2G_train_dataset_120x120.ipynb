{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_type = {'Dose25', 'Dose50', 'Dose75','Dose100', }\n",
    "data_type = 'Dose25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = './Medical_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "female_arr_tr = ['female_1.mat','female_3.mat','female_4.mat','female_5.mat',\n",
    "             'female_6.mat','female_7.mat','female_8.mat','female_9.mat','female_10.mat',\n",
    "             'female_11.mat','female_12.mat',]\n",
    "\n",
    "female_arr_te = ['female_13.mat','female_14.mat','female_15.mat',]\n",
    "\n",
    "male_arr_tr = ['male_1.mat','male_2.mat','male_3.mat','male_4.mat','male_5.mat',\n",
    "             'male_6.mat','male_7.mat','male_8.mat','male_9.mat','male_10.mat',\n",
    "             'male_11.mat',]\n",
    "\n",
    "male_arr_te = ['male_12.mat','male_13.mat']\n",
    "\n",
    "name_arr_tr = ['female_1.mat','female_3.mat','female_4.mat','female_5.mat',\n",
    "             'female_6.mat','female_7.mat','female_8.mat','female_9.mat','female_10.mat',\n",
    "             'female_11.mat','female_12.mat','male_1.mat','male_2.mat','male_3.mat','male_4.mat','male_5.mat',\n",
    "             'male_6.mat','male_7.mat','male_8.mat','male_9.mat','male_10.mat',\n",
    "             'male_11.mat',]\n",
    "\n",
    "name_arr_te = ['female_13.mat','female_14.mat','female_15.mat','male_12.mat','male_13.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "noisy_data_dir = folder_dir + data_type\n",
    "tr_noisy_images = []\n",
    "\n",
    "for name in name_arr_tr:\n",
    "    data_clean = h5py.File(noisy_data_dir + '/' + name, 'r')['img'][:]\n",
    "    tr_noisy_images.append(data_clean)\n",
    "    \n",
    "noisy = np.array(tr_noisy_images, dtype = np.float32).reshape(22*60,512,512)\n",
    "print (noisy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1320, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "clean_data_dir = folder_dir + 'Clean'\n",
    "tr_clean_images = []\n",
    "\n",
    "for name in name_arr_tr:\n",
    "    data_clean = h5py.File(clean_data_dir + '/' + name, 'r')['img_clean'][:]\n",
    "    tr_clean_images.append(data_clean)\n",
    "    \n",
    "clean = np.array(tr_clean_images, dtype = np.float32).reshape(22*60,512,512)\n",
    "print (clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def crop_random_patch(clean, noisy, size, num_patches):\n",
    "    \n",
    "    rand = random.randrange(1,100000)\n",
    "    \n",
    "    clean_patches = image.extract_patches_2d(clean, (size, size), num_patches, rand)\n",
    "    noisy_patches = image.extract_patches_2d(noisy, (size, size), num_patches, rand)\n",
    "    \n",
    "    clean_img = clean_patches.copy()\n",
    "    noisy_img = noisy_patches.copy()\n",
    "    \n",
    "    return clean_img, noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_num_patches :  20500\n",
      "patches_per_image :  16\n"
     ]
    }
   ],
   "source": [
    "max_num_patches = 20500\n",
    "patches_per_image = max_num_patches // (clean.shape[0]) + 1\n",
    "global_size = 120\n",
    "\n",
    "print ('max_num_patches : ', max_num_patches)\n",
    "print ('patches_per_image : ', patches_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of zi_patch, xi_patch :  20512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import image\n",
    "from scipy.ndimage import imread\n",
    "\n",
    "zi_patch = np.zeros((patches_per_image * (clean.shape[0]),global_size,global_size), dtype = np.float32)\n",
    "xi_patch = np.zeros((patches_per_image * (noisy.shape[0]),global_size,global_size), dtype = np.float32)\n",
    "\n",
    "patch_idx = 0\n",
    "\n",
    "for img_idx in range(noisy.shape[0]):\n",
    "    \n",
    "    clean_img = clean[img_idx]\n",
    "    noisy_img = noisy[img_idx]\n",
    "    \n",
    "    xi, zi = crop_random_patch(clean_img, noisy_img, global_size,patches_per_image)\n",
    "    \n",
    "    zi_patch[patch_idx:patch_idx+xi.shape[0]] = zi\n",
    "    xi_patch[patch_idx:patch_idx+xi.shape[0]] = xi\n",
    "\n",
    "    patch_idx += xi.shape[0]\n",
    "    \n",
    "    if patch_idx >= max_num_patches:\n",
    "        print ('len of zi_patch, xi_patch : ', patch_idx)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.imshow(zi_patch[max_num_patches-1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'G2G_train_120x120_Medical_dataset_'+str(data_type)+'.hdf5'\n",
    "# file_name = 'G2G_dataset_96x96_RealFM_WF_z_i_lambda42.hdf5'\n",
    "f = h5py.File(file_name, \"w\")\n",
    "f.create_dataset('clean_patches', data=np.array(xi_patch[:max_num_patches]))\n",
    "f.create_dataset('noisy_patches', data=np.array(zi_patch[:max_num_patches]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
